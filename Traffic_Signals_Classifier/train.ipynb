{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98e7e1b5",
   "metadata": {},
   "source": [
    "## Traffic Signals Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aeb585",
   "metadata": {},
   "source": [
    "#### Dataset From : https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970cddab",
   "metadata": {},
   "source": [
    "## The German Traffic Sign Benchmark is a multi-class, single-image classification \n",
    "\n",
    "### The benchmark has the following properties:\n",
    "\n",
    "#### Single-image, multi-class classification problem\n",
    "#### More than 40 classes\n",
    "#### More than 50,000 images in total\n",
    "#### Large, lifelike database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6182dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff2b9c",
   "metadata": {},
   "source": [
    "#### Accessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33cda0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00004.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39204</th>\n",
       "      <td>52</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "      <td>42</td>\n",
       "      <td>Train/42/00042_00007_00025.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39205</th>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>53</td>\n",
       "      <td>42</td>\n",
       "      <td>Train/42/00042_00007_00026.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39206</th>\n",
       "      <td>58</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>57</td>\n",
       "      <td>42</td>\n",
       "      <td>Train/42/00042_00007_00027.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39207</th>\n",
       "      <td>63</td>\n",
       "      <td>69</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>58</td>\n",
       "      <td>63</td>\n",
       "      <td>42</td>\n",
       "      <td>Train/42/00042_00007_00028.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39208</th>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>42</td>\n",
       "      <td>Train/42/00042_00007_00029.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39209 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId  \\\n",
       "0         27      26       5       5      22      20       20   \n",
       "1         28      27       5       6      23      22       20   \n",
       "2         29      26       6       5      24      21       20   \n",
       "3         28      27       5       6      23      22       20   \n",
       "4         28      26       5       5      23      21       20   \n",
       "...      ...     ...     ...     ...     ...     ...      ...   \n",
       "39204     52      56       5       6      47      51       42   \n",
       "39205     56      58       5       5      51      53       42   \n",
       "39206     58      62       5       6      53      57       42   \n",
       "39207     63      69       5       7      58      63       42   \n",
       "39208     68      69       7       6      62      63       42   \n",
       "\n",
       "                                 Path  \n",
       "0      Train/20/00020_00000_00000.png  \n",
       "1      Train/20/00020_00000_00001.png  \n",
       "2      Train/20/00020_00000_00002.png  \n",
       "3      Train/20/00020_00000_00003.png  \n",
       "4      Train/20/00020_00000_00004.png  \n",
       "...                               ...  \n",
       "39204  Train/42/00042_00007_00025.png  \n",
       "39205  Train/42/00042_00007_00026.png  \n",
       "39206  Train/42/00042_00007_00027.png  \n",
       "39207  Train/42/00042_00007_00028.png  \n",
       "39208  Train/42/00042_00007_00029.png  \n",
       "\n",
       "[39209 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Train.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06234b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Train/20/00020_00000_00000.png'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Path'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9303489",
   "metadata": {},
   "source": [
    "#### Plotting Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec6510aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(data['Path'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a42b7e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa50683efe0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49b577ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(data['Height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e65b7fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(data['Height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "199d322c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(data['Width'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "459e3916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(data['Width'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c83d8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33     1380\n",
       "31     1368\n",
       "34     1335\n",
       "36     1301\n",
       "35     1300\n",
       "       ... \n",
       "200       1\n",
       "172       1\n",
       "138       1\n",
       "196       1\n",
       "211       1\n",
       "Name: Height, Length: 176, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Height'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65acb78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34     1327\n",
       "35     1323\n",
       "31     1319\n",
       "33     1316\n",
       "30     1304\n",
       "       ... \n",
       "126       1\n",
       "183       1\n",
       "185       1\n",
       "196       1\n",
       "221       1\n",
       "Name: Width, Length: 187, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Width'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40e7fdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1380,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"Height\"]==33]['Width'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbb2b66",
   "metadata": {},
   "source": [
    "### Resizing Image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ad02ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "reduced_img = resize(img,(33,33))\n",
    "red_gray_img = rgb2gray(reduced_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d7f9759",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_gray_img = np.array(red_gray_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf8249f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_gray_img = np.reshape(red_gray_img,[33,33,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e466939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 33, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_gray_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad3bb75",
   "metadata": {},
   "source": [
    "### Append all Resized Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f74f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['ClassId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ea8f92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39209"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46e27e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = []\n",
    "for i in range(len(data)):\n",
    "    img = plt.imread(data['Path'][i])\n",
    "    reduced_img = resize(img,(33,33))\n",
    "    gray_img = rgb2gray(reduced_img)\n",
    "    gray_red_img = np.reshape(np.array(gray_img),[33,33,1])\n",
    "    pixels.append(gray_red_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "754c59ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 33, 33, 1)\n"
     ]
    }
   ],
   "source": [
    "pixels = np.array(pixels)\n",
    "print(pixels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8332833a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39209,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c06137",
   "metadata": {},
   "source": [
    "#### Splitting Images into Train and Test images for Validation Purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08c3874f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 22:55:56.432640: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-08 22:55:56.432657: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 43)\n",
      "(31367, 33, 33, 1)\n",
      "(7842, 33, 33, 1)\n",
      "(31367, 43)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y)\n",
    "print(y.shape)\n",
    "x_train,x_test,y_train,y_test = train_test_split(pixels,y,test_size=0.2,random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01ae6bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Dropout,Dense,Flatten,Activation\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296ebcc6",
   "metadata": {},
   "source": [
    "## CNN Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aeacc531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 31, 31, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 31, 31, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 13, 13, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 43)                44075     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 43)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,083\n",
      "Trainable params: 118,827\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 22:55:58.877631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-08 22:55:58.877799: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-08 22:55:58.877840: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-08 22:55:58.877877: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-08 22:55:58.877912: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-07-08 22:55:58.877948: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-07-08 22:55:58.877982: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-08 22:55:58.878016: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-08 22:55:58.878051: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-07-08 22:55:58.878057: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-07-08 22:55:58.878477: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64,kernel_size=3,input_shape=pixels.shape[1:],activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64,kernel_size=3,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64,kernel_size=3,activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(43,kernel_initializer='uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class myCallback(callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('loss')<0.038):\n",
    "            print(\"\\nReached 98% val_accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "callback = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a68c4fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799a1bd",
   "metadata": {},
   "source": [
    "### Model Creation Complete. Now Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b39a5452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "307/307 [==============================] - 25s 81ms/step - loss: 0.5111 - accuracy: 0.8646 - val_loss: 3.2134 - val_accuracy: 0.2079\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 25s 81ms/step - loss: 0.0546 - accuracy: 0.9846 - val_loss: 0.1593 - val_accuracy: 0.9848\n",
      "Epoch 3/10\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9919\n",
      "Reached 98% val_accuracy so cancelling training!\n",
      "307/307 [==============================] - 24s 79ms/step - loss: 0.0287 - accuracy: 0.9919 - val_loss: 0.0344 - val_accuracy: 0.9921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa499542da0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(pixels,y,batch_size =128, epochs= 10,validation_data=[x_test,y_test],callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b914a9",
   "metadata": {},
   "source": [
    "#### Accessing Test-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20fde8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3dc8dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>Test/00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>Test/00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>Test/00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>Test/00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>Test/00004.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12625</th>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>Test/12625.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12626</th>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>Test/12626.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12627</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>Test/12627.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12628</th>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>Test/12628.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12629</th>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>Test/12629.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12630 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId            Path\n",
       "0         53      54       6       5      48      49       16  Test/00000.png\n",
       "1         42      45       5       5      36      40        1  Test/00001.png\n",
       "2         48      52       6       6      43      47       38  Test/00002.png\n",
       "3         27      29       5       5      22      24       33  Test/00003.png\n",
       "4         60      57       5       5      55      52       11  Test/00004.png\n",
       "...      ...     ...     ...     ...     ...     ...      ...             ...\n",
       "12625     42      41       5       6      37      36       12  Test/12625.png\n",
       "12626     50      51       6       5      45      46       33  Test/12626.png\n",
       "12627     29      29       6       6      24      24        6  Test/12627.png\n",
       "12628     48      49       5       6      43      44        7  Test/12628.png\n",
       "12629     32      31       6       5      27      26       10  Test/12629.png\n",
       "\n",
       "[12630 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f318fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels_test = []\n",
    "test_y = test_data['ClassId']\n",
    "for i in range(len(test_data)):\n",
    "    img = plt.imread(test_data['Path'][i])\n",
    "    reduced_img = resize(img,(33,33))\n",
    "    gray_img = rgb2gray(reduced_img)\n",
    "    gray_red_img = np.reshape(np.array(gray_img),[33,33,1])\n",
    "    pixels_test.append(gray_red_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3957dde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12630, 33, 33, 1)\n"
     ]
    }
   ],
   "source": [
    "pixels_test = np.array(pixels_test)\n",
    "print(pixels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf65c9c7",
   "metadata": {},
   "source": [
    "### Predicting for Test-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e475ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 2s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(pixels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fed56ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = [np.argmax(i) for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7435f037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2be674e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input(img):\n",
    "    path = img\n",
    "    pixels_test = []\n",
    "    for i in path:\n",
    "        img = plt.imread(i)\n",
    "        reduced_img = resize(img,(33,33))\n",
    "        gray_img = rgb2gray(reduced_img)\n",
    "        gray_red_img = np.reshape(np.array(gray_img),[1,33,33,1])\n",
    "#         pixels_test.append(gray_red_img)\n",
    "#         print(pixels_test)\n",
    "        y_pred = model.predict(gray_red_img)\n",
    "        print()\n",
    "        print(\"Image:\",i,\" Belongs to Category :\",np.argmax(y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c06aac5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step\n",
      "\n",
      "Image: Test/00001.png  Belongs to Category : 1\n",
      "\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\n",
      "Image: Test/00002.png  Belongs to Category : 38\n",
      "\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\n",
      "Image: Test/00003.png  Belongs to Category : 33\n",
      "\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\n",
      "Image: Test/00004.png  Belongs to Category : 11\n",
      "\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "\n",
      "Image: Test/00005.png  Belongs to Category : 38\n",
      "\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\n",
      "Image: Test/00006.png  Belongs to Category : 18\n",
      "\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\n",
      "Image: Test/00007.png  Belongs to Category : 12\n",
      "\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "\n",
      "Image: Test/00008.png  Belongs to Category : 25\n",
      "\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "\n",
      "Image: Test/00009.png  Belongs to Category : 35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input(test_data['Path'][1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7f387e",
   "metadata": {},
   "source": [
    "### Saving Model as JSON with weights included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f396e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "570bfda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('traffic_signal_model.json','w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95ff6d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"traffic_signal_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054612ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
